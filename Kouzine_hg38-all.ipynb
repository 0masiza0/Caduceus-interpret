{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8197c79-f865-4370-84ab-d2e44c880673",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402e3cae-5f0e-4303-8fa9-3becbc4f75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5fd3f9-5f2d-40ee-89c8-d5f57e8370dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from caduceus.Sparse_vector.sparse_vector import SparseVector\n",
    "import os\n",
    "from joblib import load, dump, Parallel, delayed\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d9e34e-3a5b-4376-afc6-e88b99efec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a24dd006-6434-438b-90ad-32e16d0875fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938227b-488c-43b0-a589-a6c015ecae24",
   "metadata": {},
   "source": [
    "# Data Preparation & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad7cb3a-874c-48cf-9664-10e5c5d801f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chrom_names = [f'chr{i}' for i in list(range(1, 23)) + ['X', 'Y','M']]\n",
    "\n",
    "def chrom_reader(chrom):\n",
    "    files = sorted([i for i in os.listdir(f'./caduceus/z_dna/hg38_dna/') if f\"{chrom}_\" in i])\n",
    "    return ''.join([load(f\"./caduceus/z_dna/hg38_dna/{file}\") for file in files])\n",
    "\n",
    "DNA = {chrom:chrom_reader(chrom) for chrom in tqdm(chrom_names)}\n",
    "lens_of_chroms = {chrom: len(DNA[chrom]) for chrom in DNA}\n",
    "ZDNA = load('./caduceus/ZDNA_cousine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d06cfd-d9dc-4372-a99e-aebe9415e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/25 [01:26<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms,\n",
    "                 dna_source,\n",
    "                 labels_source, intervals, lrp_feat=[]):\n",
    "        self.chroms = chroms\n",
    "        #self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        #self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        self.lrp_feat = lrp_feat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        dna_OHE = self.le.transform(list(self.dna_source[chrom][begin:end].upper()))\n",
    "        \n",
    "        dna_letters = list(self.dna_source[chrom][begin:end].upper())\n",
    "\n",
    "        #X = dna_OHE.astype(np.float32)\n",
    "        X = \"\".join(dna_letters)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        if len(self.lrp_feat) > 0:\n",
    "            X = X[:,np.sort(self.lrp_feat)]\n",
    "\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f5c365-7fe9-420b-bdd0-dcb51d3e6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "equalized = load('./caduceus/hg38_kouzine_intervals_512-yana.pkl')\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]\n",
    "\n",
    "train_intervals, test_intervals = train_test_split(equalized, test_size=0.2, shuffle=True) \n",
    "train_intervals, val_intervals = train_test_split(train_intervals, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e0298a5-17e2-4e86-b853-e088adb6cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "params = {'batch_size':32,#32,\n",
    "          'num_workers':4,#16,\n",
    "          'shuffle':True}\n",
    "\n",
    "\n",
    "train_dataset = Dataset(chrom_names, \n",
    "                       DNA, \n",
    "                       ZDNA, train_intervals, lrp_feat = [])\n",
    "\n",
    "test_dataset = Dataset(chrom_names, \n",
    "                       DNA, \n",
    "                       ZDNA, test_intervals, lrp_feat = [])\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76879bdd-8ba0-4a05-97f5-06dd548bd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb19750-f884-4fad-b6ec-5cce1db2ef5f",
   "metadata": {},
   "source": [
    "## Модель учитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c28c1a-10d6-4c70-84bb-4f3b564c63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdna\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "def load_model(checkpoint=None):\n",
    "    model_name = \"kuleshov-group/caduceus-ph_seqlen-1k_d_model-256_n_layer-4_lr-8e-3\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name, \n",
    "                                                        trust_remote_code=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    model.lm_head = nn.Sequential(\n",
    "        nn.Linear(in_features=256, out_features=2, bias=False)\n",
    "    )\n",
    "    \n",
    "    if checkpoint is not None:\n",
    "        model.load_state_dict(torch.load(checkpoint, weights_only=True))\n",
    "        model.eval()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86a1d9c4-9761-427e-9daf-7be0b370a5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for kuleshov-group/caduceus-ph_seqlen-1k_d_model-256_n_layer-4_lr-8e-3 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kuleshov-group/caduceus-ph_seqlen-1k_d_model-256_n_layer-4_lr-8e-3.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    }
   ],
   "source": [
    "teacher, tokenizer = load_model('caduceus/zdna_2exp_5ep_0.863.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f5980d1-8924-4663-a5d1-dcc8baee9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaduceusForMaskedLM(\n",
       "  (caduceus): Caduceus(\n",
       "    (backbone): CaduceusMixerModel(\n",
       "      (embeddings): CaduceusEmbeddings(\n",
       "        (word_embeddings): Embedding(16, 256)\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x Block(\n",
       "          (mixer): BiMambaWrapper(\n",
       "            (mamba_fwd): Mamba(\n",
       "              (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
       "              (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "            (mamba_rev): Mamba(\n",
       "              (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=512, out_features=48, bias=False)\n",
       "              (dt_proj): Linear(in_features=16, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): RMSNorm()\n",
       "        )\n",
       "      )\n",
       "      (norm_f): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d12ecba-2c4d-4957-a9e6-999383d9aaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, teacher.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e7195-1db6-416f-8b99-f85d8ffaf034",
   "metadata": {},
   "source": [
    "## Модель ученик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d647a652-bbe4-4fb8-8fc9-785347796920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "import sys\n",
    "\n",
    "from mamba_lrp.model.mamba_huggingface import ModifiedMambaForCausalLM\n",
    "from mamba_lrp.model.utils import *\n",
    "from mamba_lrp.lrp.utils import relevance_propagation\n",
    "from mamba_lrp.dataset.general_dataset import get_sst_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f536e79f-566b-4c08-94e1-2916230676ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at state-spaces/mamba-130m-hf were not used when initializing MambaForCausalLM: ['backbone.layers.10.mixer.A_log', 'backbone.layers.10.mixer.D', 'backbone.layers.10.mixer.conv1d.bias', 'backbone.layers.10.mixer.conv1d.weight', 'backbone.layers.10.mixer.dt_proj.bias', 'backbone.layers.10.mixer.dt_proj.weight', 'backbone.layers.10.mixer.in_proj.weight', 'backbone.layers.10.mixer.out_proj.weight', 'backbone.layers.10.mixer.x_proj.weight', 'backbone.layers.10.norm.weight', 'backbone.layers.11.mixer.A_log', 'backbone.layers.11.mixer.D', 'backbone.layers.11.mixer.conv1d.bias', 'backbone.layers.11.mixer.conv1d.weight', 'backbone.layers.11.mixer.dt_proj.bias', 'backbone.layers.11.mixer.dt_proj.weight', 'backbone.layers.11.mixer.in_proj.weight', 'backbone.layers.11.mixer.out_proj.weight', 'backbone.layers.11.mixer.x_proj.weight', 'backbone.layers.11.norm.weight', 'backbone.layers.12.mixer.A_log', 'backbone.layers.12.mixer.D', 'backbone.layers.12.mixer.conv1d.bias', 'backbone.layers.12.mixer.conv1d.weight', 'backbone.layers.12.mixer.dt_proj.bias', 'backbone.layers.12.mixer.dt_proj.weight', 'backbone.layers.12.mixer.in_proj.weight', 'backbone.layers.12.mixer.out_proj.weight', 'backbone.layers.12.mixer.x_proj.weight', 'backbone.layers.12.norm.weight', 'backbone.layers.13.mixer.A_log', 'backbone.layers.13.mixer.D', 'backbone.layers.13.mixer.conv1d.bias', 'backbone.layers.13.mixer.conv1d.weight', 'backbone.layers.13.mixer.dt_proj.bias', 'backbone.layers.13.mixer.dt_proj.weight', 'backbone.layers.13.mixer.in_proj.weight', 'backbone.layers.13.mixer.out_proj.weight', 'backbone.layers.13.mixer.x_proj.weight', 'backbone.layers.13.norm.weight', 'backbone.layers.14.mixer.A_log', 'backbone.layers.14.mixer.D', 'backbone.layers.14.mixer.conv1d.bias', 'backbone.layers.14.mixer.conv1d.weight', 'backbone.layers.14.mixer.dt_proj.bias', 'backbone.layers.14.mixer.dt_proj.weight', 'backbone.layers.14.mixer.in_proj.weight', 'backbone.layers.14.mixer.out_proj.weight', 'backbone.layers.14.mixer.x_proj.weight', 'backbone.layers.14.norm.weight', 'backbone.layers.15.mixer.A_log', 'backbone.layers.15.mixer.D', 'backbone.layers.15.mixer.conv1d.bias', 'backbone.layers.15.mixer.conv1d.weight', 'backbone.layers.15.mixer.dt_proj.bias', 'backbone.layers.15.mixer.dt_proj.weight', 'backbone.layers.15.mixer.in_proj.weight', 'backbone.layers.15.mixer.out_proj.weight', 'backbone.layers.15.mixer.x_proj.weight', 'backbone.layers.15.norm.weight', 'backbone.layers.16.mixer.A_log', 'backbone.layers.16.mixer.D', 'backbone.layers.16.mixer.conv1d.bias', 'backbone.layers.16.mixer.conv1d.weight', 'backbone.layers.16.mixer.dt_proj.bias', 'backbone.layers.16.mixer.dt_proj.weight', 'backbone.layers.16.mixer.in_proj.weight', 'backbone.layers.16.mixer.out_proj.weight', 'backbone.layers.16.mixer.x_proj.weight', 'backbone.layers.16.norm.weight', 'backbone.layers.17.mixer.A_log', 'backbone.layers.17.mixer.D', 'backbone.layers.17.mixer.conv1d.bias', 'backbone.layers.17.mixer.conv1d.weight', 'backbone.layers.17.mixer.dt_proj.bias', 'backbone.layers.17.mixer.dt_proj.weight', 'backbone.layers.17.mixer.in_proj.weight', 'backbone.layers.17.mixer.out_proj.weight', 'backbone.layers.17.mixer.x_proj.weight', 'backbone.layers.17.norm.weight', 'backbone.layers.18.mixer.A_log', 'backbone.layers.18.mixer.D', 'backbone.layers.18.mixer.conv1d.bias', 'backbone.layers.18.mixer.conv1d.weight', 'backbone.layers.18.mixer.dt_proj.bias', 'backbone.layers.18.mixer.dt_proj.weight', 'backbone.layers.18.mixer.in_proj.weight', 'backbone.layers.18.mixer.out_proj.weight', 'backbone.layers.18.mixer.x_proj.weight', 'backbone.layers.18.norm.weight', 'backbone.layers.19.mixer.A_log', 'backbone.layers.19.mixer.D', 'backbone.layers.19.mixer.conv1d.bias', 'backbone.layers.19.mixer.conv1d.weight', 'backbone.layers.19.mixer.dt_proj.bias', 'backbone.layers.19.mixer.dt_proj.weight', 'backbone.layers.19.mixer.in_proj.weight', 'backbone.layers.19.mixer.out_proj.weight', 'backbone.layers.19.mixer.x_proj.weight', 'backbone.layers.19.norm.weight', 'backbone.layers.20.mixer.A_log', 'backbone.layers.20.mixer.D', 'backbone.layers.20.mixer.conv1d.bias', 'backbone.layers.20.mixer.conv1d.weight', 'backbone.layers.20.mixer.dt_proj.bias', 'backbone.layers.20.mixer.dt_proj.weight', 'backbone.layers.20.mixer.in_proj.weight', 'backbone.layers.20.mixer.out_proj.weight', 'backbone.layers.20.mixer.x_proj.weight', 'backbone.layers.20.norm.weight', 'backbone.layers.21.mixer.A_log', 'backbone.layers.21.mixer.D', 'backbone.layers.21.mixer.conv1d.bias', 'backbone.layers.21.mixer.conv1d.weight', 'backbone.layers.21.mixer.dt_proj.bias', 'backbone.layers.21.mixer.dt_proj.weight', 'backbone.layers.21.mixer.in_proj.weight', 'backbone.layers.21.mixer.out_proj.weight', 'backbone.layers.21.mixer.x_proj.weight', 'backbone.layers.21.norm.weight', 'backbone.layers.22.mixer.A_log', 'backbone.layers.22.mixer.D', 'backbone.layers.22.mixer.conv1d.bias', 'backbone.layers.22.mixer.conv1d.weight', 'backbone.layers.22.mixer.dt_proj.bias', 'backbone.layers.22.mixer.dt_proj.weight', 'backbone.layers.22.mixer.in_proj.weight', 'backbone.layers.22.mixer.out_proj.weight', 'backbone.layers.22.mixer.x_proj.weight', 'backbone.layers.22.norm.weight', 'backbone.layers.23.mixer.A_log', 'backbone.layers.23.mixer.D', 'backbone.layers.23.mixer.conv1d.bias', 'backbone.layers.23.mixer.conv1d.weight', 'backbone.layers.23.mixer.dt_proj.bias', 'backbone.layers.23.mixer.dt_proj.weight', 'backbone.layers.23.mixer.in_proj.weight', 'backbone.layers.23.mixer.out_proj.weight', 'backbone.layers.23.mixer.x_proj.weight', 'backbone.layers.23.norm.weight', 'backbone.layers.4.mixer.A_log', 'backbone.layers.4.mixer.D', 'backbone.layers.4.mixer.conv1d.bias', 'backbone.layers.4.mixer.conv1d.weight', 'backbone.layers.4.mixer.dt_proj.bias', 'backbone.layers.4.mixer.dt_proj.weight', 'backbone.layers.4.mixer.in_proj.weight', 'backbone.layers.4.mixer.out_proj.weight', 'backbone.layers.4.mixer.x_proj.weight', 'backbone.layers.4.norm.weight', 'backbone.layers.5.mixer.A_log', 'backbone.layers.5.mixer.D', 'backbone.layers.5.mixer.conv1d.bias', 'backbone.layers.5.mixer.conv1d.weight', 'backbone.layers.5.mixer.dt_proj.bias', 'backbone.layers.5.mixer.dt_proj.weight', 'backbone.layers.5.mixer.in_proj.weight', 'backbone.layers.5.mixer.out_proj.weight', 'backbone.layers.5.mixer.x_proj.weight', 'backbone.layers.5.norm.weight', 'backbone.layers.6.mixer.A_log', 'backbone.layers.6.mixer.D', 'backbone.layers.6.mixer.conv1d.bias', 'backbone.layers.6.mixer.conv1d.weight', 'backbone.layers.6.mixer.dt_proj.bias', 'backbone.layers.6.mixer.dt_proj.weight', 'backbone.layers.6.mixer.in_proj.weight', 'backbone.layers.6.mixer.out_proj.weight', 'backbone.layers.6.mixer.x_proj.weight', 'backbone.layers.6.norm.weight', 'backbone.layers.7.mixer.A_log', 'backbone.layers.7.mixer.D', 'backbone.layers.7.mixer.conv1d.bias', 'backbone.layers.7.mixer.conv1d.weight', 'backbone.layers.7.mixer.dt_proj.bias', 'backbone.layers.7.mixer.dt_proj.weight', 'backbone.layers.7.mixer.in_proj.weight', 'backbone.layers.7.mixer.out_proj.weight', 'backbone.layers.7.mixer.x_proj.weight', 'backbone.layers.7.norm.weight', 'backbone.layers.8.mixer.A_log', 'backbone.layers.8.mixer.D', 'backbone.layers.8.mixer.conv1d.bias', 'backbone.layers.8.mixer.conv1d.weight', 'backbone.layers.8.mixer.dt_proj.bias', 'backbone.layers.8.mixer.dt_proj.weight', 'backbone.layers.8.mixer.in_proj.weight', 'backbone.layers.8.mixer.out_proj.weight', 'backbone.layers.8.mixer.x_proj.weight', 'backbone.layers.8.norm.weight', 'backbone.layers.9.mixer.A_log', 'backbone.layers.9.mixer.D', 'backbone.layers.9.mixer.conv1d.bias', 'backbone.layers.9.mixer.conv1d.weight', 'backbone.layers.9.mixer.dt_proj.bias', 'backbone.layers.9.mixer.dt_proj.weight', 'backbone.layers.9.mixer.in_proj.weight', 'backbone.layers.9.mixer.out_proj.weight', 'backbone.layers.9.mixer.x_proj.weight', 'backbone.layers.9.norm.weight']\n",
      "- This IS expected if you are initializing MambaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MambaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MambaForCausalLM were not initialized from the model checkpoint at state-spaces/mamba-130m-hf and are newly initialized because the shapes did not match:\n",
      "- backbone.embeddings.weight: found shape torch.Size([50280, 768]) in the checkpoint and torch.Size([50280, 256]) in the model instantiated\n",
      "- backbone.layers.0.mixer.A_log: found shape torch.Size([1536, 16]) in the checkpoint and torch.Size([512, 16]) in the model instantiated\n",
      "- backbone.layers.0.mixer.D: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.0.mixer.conv1d.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.0.mixer.conv1d.weight: found shape torch.Size([1536, 1, 4]) in the checkpoint and torch.Size([512, 1, 4]) in the model instantiated\n",
      "- backbone.layers.0.mixer.dt_proj.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.0.mixer.dt_proj.weight: found shape torch.Size([1536, 48]) in the checkpoint and torch.Size([512, 48]) in the model instantiated\n",
      "- backbone.layers.0.mixer.in_proj.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
      "- backbone.layers.0.mixer.out_proj.weight: found shape torch.Size([768, 1536]) in the checkpoint and torch.Size([256, 512]) in the model instantiated\n",
      "- backbone.layers.0.mixer.x_proj.weight: found shape torch.Size([80, 1536]) in the checkpoint and torch.Size([80, 512]) in the model instantiated\n",
      "- backbone.layers.0.norm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
      "- backbone.layers.1.mixer.A_log: found shape torch.Size([1536, 16]) in the checkpoint and torch.Size([512, 16]) in the model instantiated\n",
      "- backbone.layers.1.mixer.D: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.1.mixer.conv1d.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.1.mixer.conv1d.weight: found shape torch.Size([1536, 1, 4]) in the checkpoint and torch.Size([512, 1, 4]) in the model instantiated\n",
      "- backbone.layers.1.mixer.dt_proj.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.1.mixer.dt_proj.weight: found shape torch.Size([1536, 48]) in the checkpoint and torch.Size([512, 48]) in the model instantiated\n",
      "- backbone.layers.1.mixer.in_proj.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
      "- backbone.layers.1.mixer.out_proj.weight: found shape torch.Size([768, 1536]) in the checkpoint and torch.Size([256, 512]) in the model instantiated\n",
      "- backbone.layers.1.mixer.x_proj.weight: found shape torch.Size([80, 1536]) in the checkpoint and torch.Size([80, 512]) in the model instantiated\n",
      "- backbone.layers.1.norm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
      "- backbone.layers.2.mixer.A_log: found shape torch.Size([1536, 16]) in the checkpoint and torch.Size([512, 16]) in the model instantiated\n",
      "- backbone.layers.2.mixer.D: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.2.mixer.conv1d.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.2.mixer.conv1d.weight: found shape torch.Size([1536, 1, 4]) in the checkpoint and torch.Size([512, 1, 4]) in the model instantiated\n",
      "- backbone.layers.2.mixer.dt_proj.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.2.mixer.dt_proj.weight: found shape torch.Size([1536, 48]) in the checkpoint and torch.Size([512, 48]) in the model instantiated\n",
      "- backbone.layers.2.mixer.in_proj.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
      "- backbone.layers.2.mixer.out_proj.weight: found shape torch.Size([768, 1536]) in the checkpoint and torch.Size([256, 512]) in the model instantiated\n",
      "- backbone.layers.2.mixer.x_proj.weight: found shape torch.Size([80, 1536]) in the checkpoint and torch.Size([80, 512]) in the model instantiated\n",
      "- backbone.layers.2.norm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
      "- backbone.layers.3.mixer.A_log: found shape torch.Size([1536, 16]) in the checkpoint and torch.Size([512, 16]) in the model instantiated\n",
      "- backbone.layers.3.mixer.D: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.3.mixer.conv1d.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.3.mixer.conv1d.weight: found shape torch.Size([1536, 1, 4]) in the checkpoint and torch.Size([512, 1, 4]) in the model instantiated\n",
      "- backbone.layers.3.mixer.dt_proj.bias: found shape torch.Size([1536]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- backbone.layers.3.mixer.dt_proj.weight: found shape torch.Size([1536, 48]) in the checkpoint and torch.Size([512, 48]) in the model instantiated\n",
      "- backbone.layers.3.mixer.in_proj.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([1024, 256]) in the model instantiated\n",
      "- backbone.layers.3.mixer.out_proj.weight: found shape torch.Size([768, 1536]) in the checkpoint and torch.Size([256, 512]) in the model instantiated\n",
      "- backbone.layers.3.mixer.x_proj.weight: found shape torch.Size([80, 1536]) in the checkpoint and torch.Size([80, 512]) in the model instantiated\n",
      "- backbone.layers.3.norm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
      "- backbone.norm_f.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hf_mamba_classification import MambaForSequenceClassification # https://github.com/getorca/mamba_for_sequence_classification/blob/main/src/hf_mamba_classification.py\n",
    "\n",
    "model_path = 'state-spaces/mamba-130m-hf'\n",
    "\n",
    "student = MambaForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=2, \n",
    "    use_cache=True,\n",
    "    intermediate_size=512,\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=4,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "resize_token_embeddings(student, len(tokenizer))\n",
    "student.lm_head = torch.nn.Linear(256, 2, bias=True)\n",
    "student.load_state_dict(torch.load('mamba-gue-for-distil.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ada21f9-44d5-4bd2-95ef-ed4b98a0c13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaForCausalLM(\n",
       "  (backbone): MambaModel(\n",
       "    (embeddings): Embedding(12, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x MambaBlock(\n",
       "        (norm): MambaRMSNorm(256, eps=1e-05)\n",
       "        (mixer): MambaMixer(\n",
       "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
       "          (act): SiLU()\n",
       "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (x_proj): Linear(in_features=512, out_features=80, bias=False)\n",
       "          (dt_proj): Linear(in_features=48, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): MambaRMSNorm(256, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15c3e8c7-69de-443b-87cf-19b84bc12fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1886978"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, student.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2731f361-e5d7-4be8-ad76-11a13af7e45d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaForCausalLM(\n",
       "  (backbone): MambaModel(\n",
       "    (embeddings): Embedding(12, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x MambaBlock(\n",
       "        (norm): MambaRMSNorm(256, eps=1e-05)\n",
       "        (mixer): MambaMixer(\n",
       "          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)\n",
       "          (act): SiLU()\n",
       "          (in_proj): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (x_proj): Linear(in_features=512, out_features=80, bias=False)\n",
       "          (dt_proj): Linear(in_features=48, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_f): MambaRMSNorm(256, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.cuda()\n",
    "teacher.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0d517e1-a003-4ad4-8793-8cd0f528b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = teacher(**tokenizer(train_dataset[0][0], return_tensors='pt', add_special_tokens=False).to(device))\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21c74d72-ec7b-4aa0-a804-62418216ae49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9602, -0.0840],\n",
       "         [ 0.2702, -0.0568],\n",
       "         [-0.0995, -0.5179],\n",
       "         ...,\n",
       "         [ 0.1558,  0.1106],\n",
       "         [-0.0428, -1.2408],\n",
       "         [ 0.2647, -0.6359]]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = student(**tokenizer(train_dataset[0][0], return_tensors='pt', add_special_tokens=False).to(device))\n",
    "outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247cc28-4928-4084-8ae6-a4ca370ee682",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e48f6c48-99ee-410d-bca9-6e7fbf60cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 753/753 [01:56<00:00,  6.47it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:53, 417.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5009487227569068 0.4996799522040411 0.95715234375\n",
      "Epoch [1/5], Loss: 0.0471, F1: 0.50, MCC: 0.50, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:02<00:00,  6.16it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:55, 400.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47344931111990574 0.43772663388393235 0.960171875\n",
      "Epoch [2/5], Loss: 0.0412, F1: 0.44, MCC: 0.47, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:03<00:00,  6.08it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:57, 383.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43267865028194497 0.3939089441161382 0.95799609375\n",
      "Epoch [3/5], Loss: 0.0401, F1: 0.39, MCC: 0.43, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:07<00:00,  5.92it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:05<01:03, 352.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5057119381368708 0.47586584211463184 0.9613125\n",
      "Epoch [4/5], Loss: 0.0395, F1: 0.48, MCC: 0.51, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:08<00:00,  5.88it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:59, 373.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480924048030009 0.4468616728679255 0.96073828125\n",
      "Epoch [5/5], Loss: 0.0389, F1: 0.45, MCC: 0.48, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(predictions, labels):\n",
    "    predictions = np.argmax(predictions[0], axis=-1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions),\n",
    "            'mcc': matthews_corrcoef(labels, predictions),\n",
    "            'f1': f1_score(labels, predictions)\n",
    "           }\n",
    "\n",
    "def eval(n=500):\n",
    "    student.eval()\n",
    "    mcc = []\n",
    "    acc = []\n",
    "    f1 = []\n",
    "    i = 0\n",
    "    for batch in tqdm(test_dataset):\n",
    "        if batch[1].sum() == 0:\n",
    "            continue\n",
    "        if i == n:\n",
    "            break\n",
    "        inputs = torch.Tensor(tokenizer(batch[0], return_tensors='pt', add_special_tokens=False)['input_ids']).to(device)\n",
    "        labels = torch.Tensor(batch[1]).to(device)\n",
    "        \n",
    "        # Получаем логиты от обеих моделей\n",
    "        with torch.no_grad():\n",
    "            student_logits = student(inputs).logits\n",
    "    \n",
    "        metrics = compute_metrics(student_logits.cpu(), labels.cpu())\n",
    "        mcc.append(metrics['mcc'])\n",
    "        acc.append(metrics['accuracy'])\n",
    "        f1.append(metrics['f1'])\n",
    "        i += 1\n",
    "    \n",
    "    print(np.mean(mcc), np.mean(f1), np.mean(acc))\n",
    "    return np.mean(mcc), np.mean(f1), np.mean(acc)\n",
    "    \n",
    "# class DistillationLoss(nn.Module):\n",
    "#     def __init__(self, alpha=0.5, temperature=2.0):\n",
    "#         super(DistillationLoss, self).__init__()\n",
    "#         self.alpha = alpha  # Вес для стандартной кросс-энтропии\n",
    "#         self.temperature = temperature  # Температура для дистилляции (упрощает логиты учителя)\n",
    "\n",
    "#     def forward(self, student_logits, teacher_logits, labels):\n",
    "#         # Стандартная кросс-энтропия (потеря на реальных метках)\n",
    "#         ce_loss = F.cross_entropy(student_logits, labels)\n",
    "        \n",
    "#         # Потеря дистилляции\n",
    "#         student_probs = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "#         teacher_probs = F.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "        \n",
    "#         distillation_loss = F.kl_div(student_probs, teacher_probs, reduction='batchmean') * (self.temperature ** 2)\n",
    "        \n",
    "#         # Общая потеря (комбинированная)\n",
    "#         loss = self.alpha * ce_loss + (1.0 - self.alpha) * distillation_loss\n",
    "#         return loss\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=2.0):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.alpha = alpha  # Вес для стандартной кросс-энтропии\n",
    "        self.temperature = temperature  # Температура для дистилляции (упрощает логиты учителя)\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, labels):\n",
    "        # Преобразуем logits в нужную форму\n",
    "        # student_logits: (batch_size, seq_len, num_classes)\n",
    "        # labels: (batch_size, seq_len)\n",
    "        \n",
    "        # Стандартная кросс-энтропия (потеря на реальных метках)\n",
    "        # Мы учитываем, что метки имеют форму (batch_size, seq_len), и каждая метка — это индекс класса для каждого токена\n",
    "        ce_loss = F.cross_entropy(student_logits.view(-1, student_logits.size(-1)), labels.view(-1), reduction='mean')\n",
    "        \n",
    "        # Потеря дистилляции\n",
    "        student_probs = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "        teacher_probs = F.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "        \n",
    "        # KL-дивергенция между логитами ученика и учителя (по всем токенам и всем классам)\n",
    "        distillation_loss = F.kl_div(student_probs.view(-1, student_probs.size(-1)), teacher_probs.view(-1, teacher_probs.size(-1)), reduction='mean') * (self.temperature ** 2)\n",
    "        \n",
    "        # Общая потеря (комбинированная)\n",
    "        loss = self.alpha * ce_loss + (1.0 - self.alpha) * distillation_loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "def train_student_model(student_model, teacher_model, train_loader, optimizer, device, num_epochs=10, alpha=0.5, temperature=2.0):\n",
    "    distillation_loss_fn = DistillationLoss(alpha=alpha, temperature=temperature)\n",
    "    best_f1 = 0\n",
    "    \n",
    "    # Переводим модели в режим тренировки\n",
    "    student_model.train()\n",
    "    teacher_model.eval()  # Модель учителя в режиме оценки\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() \n",
    "        \n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs = tokenizer(batch[0], return_tensors='pt', add_special_tokens=False).to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            \n",
    "            # Получаем логиты от обеих моделей\n",
    "            with torch.no_grad():  # Учитель не обучается, только инференс\n",
    "                teacher_logits = teacher_model(**inputs).logits\n",
    "            \n",
    "            student_logits = student_model(**inputs).logits\n",
    "            # print(teacher_logits.shape, student_logits.shape, labels.shape)\n",
    "            # print(student_logits)\n",
    "            # print(compute_metrics(student_logits.cpu().detach().numpy(), labels.type(torch.LongTensor).cpu()))\n",
    "                  \n",
    "            # Вычисляем потерю\n",
    "            student_logits = student_logits.view(-1, student_logits.size(-1)).to(device)\n",
    "            labels = labels.view(-1).type(torch.LongTensor).to(device)\n",
    "            # ce_loss = F.cross_entropy(student_logits, labels, reduction='mean')\n",
    "            \n",
    "            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Оценка точности\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        mcc, f1, acc = eval()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, F1: {f1:.2f}, MCC: {mcc:.2f}, Accuracy: {acc:.2f}')\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(student_model.state_dict(), f'zdna_f1_{best_f1}.pt')\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "# Предположим, что у нас есть модели student_model и teacher_model, а также train_loader с данными\n",
    "\n",
    "# optimizer = optim.Adam(student.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=1e-3, betas=(0.95, 0.9))\n",
    "\n",
    "# Устройство (GPU или CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Переносим модели на устройство\n",
    "student.to(device)\n",
    "teacher.to(device)\n",
    "\n",
    "# Обучение модели ученика\n",
    "train_student_model(student, teacher, loader_test, optimizer, device, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "35fd3776-2deb-47e1-bec2-b13628d994cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [01:59<00:00,  6.28it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:05<01:02, 356.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0371, F1: 0.52, MCC: 0.55, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:06<00:00,  5.97it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:56, 391.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.0366, F1: 0.52, MCC: 0.55, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:09<00:00,  5.82it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:05<01:00, 365.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.0363, F1: 0.52, MCC: 0.55, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "# Предположим, что у нас есть модели student_model и teacher_model, а также train_loader с данными\n",
    "\n",
    "# optimizer = optim.Adam(student.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=2e-4, betas=(0.95, 0.9))\n",
    "\n",
    "# Устройство (GPU или CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Переносим модели на устройство\n",
    "student.to(device)\n",
    "teacher.to(device)\n",
    "\n",
    "# Обучение модели ученика\n",
    "train_student_model(student, teacher, loader_test, optimizer, device, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "45bae161-daff-4c9a-ae2f-6a1b9aa3ce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.load_state_dict(torch.load('zdna_f1_0.523.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "25e1ec2f-3d2a-4494-98b6-631b315a957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [01:57<00:00,  6.41it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:57, 386.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0367, F1: 0.51, MCC: 0.54, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:03<00:00,  6.09it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:05<01:00, 366.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.0363, F1: 0.53, MCC: 0.55, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/caduceus_clone/lib/python3.9/site-packages/torch/nn/functional.py:2943: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████| 753/753 [02:05<00:00,  5.99it/s]\n",
      "  8%|██▊                                  | 1858/24071 [00:04<00:59, 375.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.0359, F1: 0.54, MCC: 0.56, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(student.parameters(), lr=2e-4, betas=(0.95, 0.9))\n",
    "\n",
    "# Обучение модели ученика\n",
    "# alpha=0.85\n",
    "train_student_model(student, teacher, loader_test, optimizer, device, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8aa3a6-7a61-441f-9863-38ba136b18f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797419ac-bfc4-4bce-a2c3-22df66f3d08b",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ff6de34-3f0c-4601-bfc9-e9ac5989906f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91295304-fb98-4ccd-8a40-5350b43ccd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "08282d99-5a4d-4abf-99ba-c11129720f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▊                                  | 1858/24071 [00:04<00:54, 409.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5118393718357392 0.4904617857087976 0.961109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5118393718357392, 0.4904617857087976, 0.961109375)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e4810-c4c1-4ad8-b55d-5af39b845a42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Interpret student LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62c16739-5678-4481-ba08-da067e8eb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "import sys\n",
    "\n",
    "from mamba_lrp.model.mamba_huggingface import ModifiedMambaForCausalLM\n",
    "from mamba_lrp.model.utils import *\n",
    "from mamba_lrp.lrp.utils import relevance_propagation\n",
    "from mamba_lrp.dataset.general_dataset import get_sst_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da7427ce-8a73-4bd7-b06d-5fd344b15db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model = ModifiedMambaForCausalLM(student, is_fast_forward_available=False)\n",
    "modified_model.eval()\n",
    "pretrained_embeddings = student.backbone.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99890160-d329-45d4-b4ec-30e9a44cb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "def interpret(seq):\n",
    "    # print(seq[0])\n",
    "    inputs = tokenizer(seq[0], return_tensors='pt', add_special_tokens=False)['input_ids']\n",
    "    # print(inputs)\n",
    "    inputs = inputs.long().to(device)\n",
    "    label = torch.tensor(seq[1]).unsqueeze(0).long().to(device)\n",
    "    \n",
    "    embeddings = pretrained_embeddings(inputs)\n",
    "    \n",
    "    R, prediction = relevance_propagation(\n",
    "        model=modified_model,\n",
    "        embeddings=embeddings,\n",
    "        targets=label,\n",
    "        n_classes=2\n",
    "    )\n",
    "    \n",
    "    tokens = []\n",
    "    for id in inputs[0]:\n",
    "        tokens.append(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens([id.item()])))\n",
    "    attributions = R[0]\n",
    "    attributions = attributions / attributions.max()\n",
    "\n",
    "    # print(attributions.shape)\n",
    "    # print(student(inputs).logits.shape)\n",
    "    return attributions\n",
    "    # Visualize the attributions\n",
    "    viz.visualize_text([viz.VisualizationDataRecord(\n",
    "        attributions,\n",
    "        torch.max(student(inputs).logits, dim=1).values.item(),\n",
    "        torch.argmax(student(inputs).logits, dim=1).item(),\n",
    "        true_class=label.item(),\n",
    "        attr_class=label.item(),\n",
    "        attr_score=attributions.sum(),\n",
    "        raw_input_ids=tokens,\n",
    "        convergence_score=None\n",
    "    )])\n",
    "    return attributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87726c3a-edb3-4346-9fb2-d34fe5d3766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = interpret(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e2573b5-ed9f-4667-b41b-b7519081f0c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.20194284e-04, -2.36713495e-05, -1.27956464e-05,  1.67269609e-05,\n",
       "        6.60531850e-06, -3.29011018e-05, -2.86573595e-05, -3.00497468e-05,\n",
       "        1.54890149e-05,  8.10637630e-06,  1.55048201e-05,  4.10308239e-05,\n",
       "       -2.15316941e-05,  3.26815425e-05, -3.06306247e-05,  2.63177717e-05,\n",
       "        3.30987386e-05,  2.67635914e-05, -4.08664200e-05,  4.08500782e-05,\n",
       "        3.92948386e-05,  4.58687828e-05, -1.24772041e-05,  4.25325597e-05,\n",
       "        5.45747607e-05,  3.50149276e-05, -2.75278453e-05,  4.70651430e-05,\n",
       "       -2.39144538e-05,  5.84691079e-05, -3.96029754e-05, -1.99875267e-05,\n",
       "        2.85731512e-05,  4.22936319e-05,  8.68133575e-05,  7.84309086e-05,\n",
       "        9.10606468e-05, -4.54844158e-05,  7.41585973e-05,  6.49573849e-05,\n",
       "        5.89480042e-05,  9.48274173e-05,  1.13000133e-04, -1.31915785e-05,\n",
       "        8.37759435e-05, -9.08606034e-06, -1.26985578e-05, -3.50881710e-05,\n",
       "        2.30031492e-05, -2.92240529e-05,  3.38749196e-05,  3.69917943e-05,\n",
       "        4.18177733e-05,  6.07498368e-05,  3.32032942e-05, -1.23357277e-05,\n",
       "        4.95915956e-05, -2.79525120e-05, -2.95724403e-05,  3.75427626e-05,\n",
       "        2.63467009e-05, -3.86369793e-05, -2.61808236e-05,  3.26849949e-05,\n",
       "        1.12592506e-05,  7.79248076e-05,  9.99774711e-05, -6.36592304e-05,\n",
       "        1.14891933e-04,  7.82200586e-05,  4.82024843e-05, -2.54035986e-05,\n",
       "       -1.95073426e-05,  3.73583352e-05, -3.70850394e-05, -4.89696067e-05,\n",
       "       -4.21010809e-05,  3.08243798e-05,  4.63639444e-05,  4.17062984e-05,\n",
       "        8.41274305e-05,  6.45526088e-05,  7.82555362e-05,  1.15238305e-04,\n",
       "       -3.29073882e-05, -3.97792464e-05,  4.74819244e-05,  6.80034937e-05,\n",
       "       -2.83055215e-05,  8.26801770e-05, -6.88502087e-06,  3.73626535e-05,\n",
       "        9.07191934e-05, -4.73987529e-05,  8.60524451e-05,  5.29361350e-05,\n",
       "       -1.31078241e-05,  5.10829195e-05, -3.34958640e-05,  3.39275721e-05,\n",
       "        5.46335104e-05,  2.13098119e-05, -2.30898368e-05,  6.88592700e-05,\n",
       "        1.96649889e-05, -1.08676124e-06,  6.40005783e-06, -1.16121782e-05,\n",
       "       -1.77277816e-05, -3.05469948e-05,  4.39934001e-06,  1.81838295e-05,\n",
       "       -3.80251877e-05, -3.03316119e-05,  1.45167924e-05,  3.74834708e-05,\n",
       "       -3.87295295e-05,  2.91535562e-05,  2.61565765e-05, -2.13944313e-05,\n",
       "       -1.09364155e-05,  5.09309066e-05, -2.60318920e-05, -1.58697549e-05,\n",
       "        1.29551136e-05,  7.24486472e-06,  2.30664518e-05, -4.23145393e-05,\n",
       "       -1.98933903e-05,  2.63125967e-05,  2.39916644e-05, -7.76814923e-05,\n",
       "        4.82826108e-05,  4.49858780e-05,  1.44324413e-05, -5.43397255e-05,\n",
       "        1.08804699e-04, -3.59329242e-05,  4.01854704e-05, -2.40147256e-05,\n",
       "       -6.50158181e-05,  1.58418625e-05,  3.51224880e-05,  5.27258380e-05,\n",
       "       -8.14604209e-05,  9.38484227e-05,  8.73398021e-05,  5.29250719e-05,\n",
       "       -4.94019623e-05,  1.32424742e-04, -2.96259532e-05,  4.03965059e-05,\n",
       "        6.21996151e-05, -3.05619542e-05, -3.66917084e-05,  1.84623041e-05,\n",
       "       -4.46667364e-05,  2.31302020e-05, -4.42993369e-05,  1.63576697e-05,\n",
       "        1.70828207e-05,  2.69187494e-05,  6.41527367e-05, -5.56920786e-05,\n",
       "       -6.80132143e-05,  7.68792961e-05,  3.52375246e-05,  1.09698420e-04,\n",
       "       -1.16814255e-04,  3.64932021e-05,  1.71254767e-04, -4.68678598e-04,\n",
       "       -3.03502398e-04, -3.20868421e-04,  5.47007403e-05,  4.75060988e-05,\n",
       "       -8.51649165e-05,  8.31325669e-05,  1.07334869e-04, -1.25706021e-04,\n",
       "        1.42336328e-04, -1.55811751e-04,  1.04445920e-04, -6.18918566e-05,\n",
       "        9.71152840e-05, -1.38865507e-04,  8.48938071e-05,  1.30579152e-04,\n",
       "        9.78552853e-05, -3.44783148e-05, -1.52421280e-05,  1.69481893e-04,\n",
       "       -9.22256877e-05, -4.59564799e-05,  2.26350734e-04,  1.13082409e-04,\n",
       "        1.30872577e-04,  2.32161925e-04,  2.84024223e-04, -6.40924482e-05,\n",
       "        1.63340243e-04,  1.36883260e-04, -1.30223736e-04,  1.37118637e-04,\n",
       "        1.55942413e-04,  2.19532536e-04, -6.56646444e-05,  2.39987596e-04,\n",
       "       -6.53983661e-05,  6.30111026e-05,  6.32867450e-05, -1.11347545e-04,\n",
       "        1.51784217e-04, -5.39379653e-05,  7.78372560e-05,  1.24689002e-04,\n",
       "       -3.26874142e-05, -2.27583532e-05,  3.41601190e-05, -7.02528559e-05,\n",
       "        4.27328632e-05, -6.33623131e-05,  4.95569438e-05, -7.79081893e-05,\n",
       "       -7.06877181e-05,  1.57614159e-05,  5.22828013e-05,  1.07558997e-04,\n",
       "       -2.41424368e-05, -1.97622794e-05, -2.84190373e-05,  1.84905184e-05,\n",
       "        4.89225204e-05, -9.32041003e-05,  5.46684496e-05,  8.77997954e-05,\n",
       "       -1.80201881e-04,  1.90230116e-04, -1.47473183e-04,  1.15305913e-04,\n",
       "       -1.21856770e-04,  1.17436801e-04, -7.70092229e-05,  1.83915923e-04,\n",
       "       -7.98516921e-05, -1.21705789e-05, -1.84063028e-05, -8.28584089e-05,\n",
       "       -1.56007212e-04, -2.06308221e-04,  1.90035753e-05, -1.43782774e-04,\n",
       "        4.16960393e-05, -3.59396479e-04, -2.56108382e-04,  1.30440603e-04,\n",
       "       -8.73385943e-05, -1.29511143e-04, -9.17174984e-05, -4.52291624e-06,\n",
       "        8.31669167e-05, -5.82197790e-05, -3.56637684e-05, -2.26675184e-05,\n",
       "       -4.58923132e-05, -3.92894835e-05, -1.26994100e-05, -4.06409708e-05,\n",
       "       -1.22823176e-05, -4.73329419e-05, -4.68461549e-05, -5.27907978e-05,\n",
       "       -5.03615338e-05, -6.10179522e-05, -6.02615546e-05, -1.18590560e-05,\n",
       "       -6.53805400e-05, -8.75095066e-05, -1.14505849e-04, -4.13949510e-06,\n",
       "        1.00549005e-04,  7.50922554e-05, -9.62887643e-05, -1.67399776e-04,\n",
       "        1.10500172e-04,  1.03582672e-04,  1.55490940e-04,  2.65197887e-04,\n",
       "       -8.41344227e-05, -5.40464644e-05,  1.50972948e-04, -1.67909820e-04,\n",
       "        1.43748606e-04,  2.76689767e-04,  1.80867792e-04,  3.11828946e-04,\n",
       "        4.91830928e-04, -2.86568247e-04, -2.70806893e-04,  7.88176258e-04,\n",
       "        6.84842875e-04,  9.41301405e-04,  1.22727698e-03,  1.19968480e-03,\n",
       "        1.70332822e-03,  1.95735623e-03,  1.22817175e-03,  1.05076272e-03,\n",
       "        1.17377657e-03, -1.03120037e-04,  8.20034242e-04, -2.28939840e-04,\n",
       "       -3.33216973e-04,  4.42960503e-04, -2.41238813e-04,  3.32463969e-04,\n",
       "        4.82395728e-04, -2.26255797e-04,  2.54441926e-04,  3.03290144e-04,\n",
       "       -9.38693411e-05, -1.65010846e-04, -2.80846816e-05,  1.86576843e-04,\n",
       "       -4.43234487e-04, -5.28118922e-04,  1.80522606e-04, -6.89735985e-04,\n",
       "       -6.42460072e-04,  8.75089027e-05, -4.70348052e-04,  2.41698610e-04,\n",
       "       -3.03694978e-04, -4.91928891e-04,  1.09241104e-04,  1.36120900e-04,\n",
       "       -3.26886511e-04,  1.70531159e-04,  2.33929648e-04, -2.26598233e-04,\n",
       "       -2.36327280e-04, -2.79237953e-04,  2.42113267e-04, -3.60487320e-04,\n",
       "        4.08831169e-04,  3.13826342e-04, -1.50831387e-04,  3.96771444e-04,\n",
       "        4.22684156e-04,  4.41306038e-04,  8.09981138e-04, -3.20463179e-04,\n",
       "        8.70696444e-04,  5.57299354e-04,  9.42158571e-04,  1.10134156e-03,\n",
       "       -2.55310064e-04,  1.33555848e-03,  8.72558740e-04,  9.30111448e-04,\n",
       "       -1.64799552e-04,  8.54855578e-04,  5.04236028e-04,  8.10771307e-04,\n",
       "       -3.38827173e-04, -4.15132847e-04,  6.42703206e-04, -3.00304004e-04,\n",
       "        2.09634367e-04,  8.42972891e-04, -1.47707388e-03, -5.45664283e-04,\n",
       "        2.59385415e-04,  1.64104440e-05, -4.66116966e-04,  8.51674646e-04,\n",
       "       -3.57984653e-04, -4.42888530e-04,  5.42108843e-04,  2.83266454e-05,\n",
       "        3.61831306e-04,  3.15985788e-04,  2.78292806e-04,  2.99409439e-04,\n",
       "        5.54366561e-04, -3.08704271e-04, -5.32709179e-04, -3.67318862e-04,\n",
       "        2.56323052e-04,  6.40489918e-04, -6.68096123e-04,  7.25496735e-04,\n",
       "        9.03155596e-04, -1.09930325e-03,  1.57601910e-03,  1.93024008e-03,\n",
       "        1.19772088e-03,  2.03130860e-03,  1.95496809e-03, -6.27915259e-04,\n",
       "        2.91305454e-03,  2.62836646e-03,  3.55615094e-03,  4.07521147e-03,\n",
       "        4.91189351e-03,  4.62780101e-03,  5.64126996e-03,  6.87064044e-03,\n",
       "        5.21439919e-03,  5.36727998e-03,  4.89560934e-03,  7.11279456e-03,\n",
       "        7.41010346e-03,  7.18420977e-03,  8.05789605e-03,  8.38593766e-03,\n",
       "       -1.37221490e-04,  3.71014141e-03,  2.93207122e-03,  2.16734782e-03,\n",
       "        2.62625079e-04,  2.88449600e-03, -1.95950401e-04,  1.38888706e-03,\n",
       "        9.75796313e-04,  5.65847964e-04,  1.58576609e-03, -5.43750823e-04,\n",
       "        1.17247400e-03,  1.10037625e-03, -1.08763890e-03, -5.52378711e-04,\n",
       "        6.93003763e-04, -2.05220531e-05,  1.31340174e-04, -9.31843650e-04,\n",
       "       -6.42255764e-04,  2.27632801e-04,  9.33974516e-05,  3.06963746e-04,\n",
       "        7.27028062e-04,  1.08624075e-03,  1.44459435e-03, -1.79148011e-03,\n",
       "        2.70032813e-03, -7.17741088e-04,  1.09869044e-03,  1.78901595e-03,\n",
       "       -1.22725940e-03,  2.20119022e-03,  2.72137532e-03,  2.65397714e-03,\n",
       "        3.45114060e-03, -1.89457089e-03,  3.15243588e-03,  2.58723646e-03,\n",
       "        3.96499317e-03,  3.75928148e-03,  4.10493836e-03,  5.01305610e-03,\n",
       "        4.29858454e-04, -6.43029402e-04,  3.42911715e-03,  8.83585948e-04,\n",
       "        1.70061039e-03,  3.62155284e-03,  3.26722488e-03,  3.10022710e-03,\n",
       "        3.16654239e-03,  5.17704664e-03,  7.72702260e-05,  3.51949781e-03,\n",
       "        4.80599049e-03, -1.85142912e-03,  5.35340048e-03, -9.98480828e-04,\n",
       "        3.96863557e-03,  4.34183842e-03,  4.13006451e-03,  8.39158706e-03,\n",
       "        6.50688680e-03,  6.24026498e-03,  6.27072901e-03,  6.18006894e-03,\n",
       "        3.30538955e-04,  8.37632176e-03,  2.37471494e-03,  4.79658926e-03,\n",
       "        2.80810683e-03,  3.83629184e-03,  6.80898223e-03,  1.78981596e-03,\n",
       "        7.15825800e-03,  7.79332453e-03,  1.36143179e-03,  1.42661789e-02,\n",
       "        1.32211735e-02,  2.06271727e-02,  1.81502346e-02,  1.37544153e-02,\n",
       "        8.62004794e-03,  2.79698856e-02,  3.18009928e-02,  3.47149521e-02,\n",
       "        7.33524412e-02,  6.88248575e-02,  3.93282548e-02,  1.67931855e-01,\n",
       "        1.08433038e-01,  1.27597615e-01,  9.12392735e-02,  1.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a6f75-0dfb-4ead-b41c-82e017c686c1",
   "metadata": {},
   "source": [
    "# IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246603ac-ad94-4323-9ef4-14674ecd1248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cad98-d5de-4795-8c22-60b868327c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d2ce2-76f5-4e8d-838d-377a06cba8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a16cf-db74-4e4d-a1c4-61e760f1ee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e73b7e39-75d8-421c-a120-77415ea01ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmer</th>\n",
       "      <th>Score</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GCGCG</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CACGC</td>\n",
       "      <td>0.6916</td>\n",
       "      <td>3201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CGC</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCGC</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGCGC</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCGTG</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CACGC</td>\n",
       "      <td>0.4842</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kmer   Score  Count\n",
       "0  GCGCG  0.8230    339\n",
       "1  CACGC  0.6916   3201\n",
       "2    CGC  0.6564    131\n",
       "3   GCGC  0.6036    217\n",
       "4  TGCGC  0.5462    108\n",
       "5  GCGTG  0.5042    827\n",
       "6  CACGC  0.4842   2121"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = ['GCGCG', 'CACGC', 'CGC', 'GCGC', 'TGCGC', 'GCGTG', 'CACGC']\n",
    "scores = [0.8230, 0.6916, 0.6564, 0.6036, 0.5462, 0.5042, 0.4842]\n",
    "counts = [339, 3201, 131, 217, 108, 827, 2121]\n",
    "pd.DataFrame({'kmer': seqs, 'Score': scores, 'Count': counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be464fdb-283a-45de-b094-425beedc2c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caduceus_backup",
   "language": "python",
   "name": "caduceus_backup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
